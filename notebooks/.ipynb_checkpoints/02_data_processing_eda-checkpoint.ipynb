{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extreme-mention",
   "metadata": {},
   "source": [
    "- Batch the dataframe by a few thousand and write tensors to a directory\n",
    "- Use that directory to train the model, Pytorch dataset can data file names as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "choice-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import h3\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-arkansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1393410053620000386</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000386</td>\n",
       "      <td>1393410053</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.58564,41.148621],[-8.585712,41.148783],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1388414676620000406</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20000406</td>\n",
       "      <td>1388414676</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.582238,41.180634],[-8.582229,41.180634],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1397662736620000081</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000081</td>\n",
       "      <td>1397662736</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.599689,41.153103],[-8.599698,41.153094],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1403885169620000669</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000669</td>\n",
       "      <td>1403885169</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610948,41.145723],[-8.610777,41.14593],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1382026245620000163</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000163</td>\n",
       "      <td>1382026245</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.632719,41.151582],[-8.632665,41.151672],[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "0  1393410053620000386         B          NaN          15.0  20000386   \n",
       "1  1388414676620000406         B          NaN           6.0  20000406   \n",
       "2  1397662736620000081         C          NaN           NaN  20000081   \n",
       "3  1403885169620000669         B          NaN          57.0  20000669   \n",
       "4  1382026245620000163         C          NaN           NaN  20000163   \n",
       "\n",
       "    TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "0  1393410053        A         False   \n",
       "1  1388414676        A         False   \n",
       "2  1397662736        A         False   \n",
       "3  1403885169        A         False   \n",
       "4  1382026245        A         False   \n",
       "\n",
       "                                            POLYLINE  \n",
       "0  [[-8.58564,41.148621],[-8.585712,41.148783],[-...  \n",
       "1  [[-8.582238,41.180634],[-8.582229,41.180634],[...  \n",
       "2  [[-8.599689,41.153103],[-8.599698,41.153094],[...  \n",
       "3  [[-8.610948,41.145723],[-8.610777,41.14593],[-...  \n",
       "4  [[-8.632719,41.151582],[-8.632665,41.151672],[...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/original_data.csv\")\n",
    "data = data.sample(30000)\n",
    "data = data.reset_index(drop=True)\n",
    "#data = pd.read_csv(\"../data/subset_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interpreted-exhibit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(data)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "undefined-league",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples / 25000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-meaning",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/crailtap/taxi-trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-wealth",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "radical-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeats(vals):\n",
    "    if len(vals) == 0:\n",
    "        return None\n",
    "    result = []\n",
    "    curr = vals[0]\n",
    "    for val in vals[1:]:\n",
    "        if val != curr:\n",
    "            result.append(curr)\n",
    "        curr = val\n",
    "    result.append(curr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "received-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlon_to_h3(latlons, res=9):\n",
    "    latlons = ast.literal_eval(latlons)\n",
    "    result = []\n",
    "    for latlon in latlons:\n",
    "        h3_id = h3.geo_to_h3(latlon[0], latlon[1], res)\n",
    "        result.append(h3_id)\n",
    "    result = remove_repeats(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-character",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-christianity",
   "metadata": {},
   "source": [
    "### Convert to H3 Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "upset-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"H3_POLYLINE\"] = data[\"POLYLINE\"].apply(latlon_to_h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collectible-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0, subset=[\"H3_POLYLINE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assured-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580336\n"
     ]
    }
   ],
   "source": [
    "data[\"len_h3\"] = data[\"H3_POLYLINE\"].apply(len)\n",
    "data = data[data[\"len_h3\"] > 1]\n",
    "print(data[\"len_h3\"].sum())\n",
    "data = data.drop(columns=[\"len_h3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-malpractice",
   "metadata": {},
   "source": [
    "### Tokenizing H3 IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "looking-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_h3_ids = data.explode(\"H3_POLYLINE\").H3_POLYLINE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pursuant-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_to_token = {}\n",
    "token_to_h3 = {}\n",
    "for i in range(len(unq_h3_ids)):\n",
    "    h3_to_token[unq_h3_ids[i]] = i\n",
    "    token_to_h3[i] = unq_h3_ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hispanic-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/tokenizers/encode_h3_to_token.pickle\", \"wb\") as f:\n",
    "    pickle.dump(h3_to_token, f)\n",
    "with open(\"../models/tokenizers/decode_token_to_h3.pickle\", \"wb\") as f:\n",
    "    pickle.dump(token_to_h3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "competitive-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(vals, val_to_token_dict):\n",
    "    result = []\n",
    "    for val in vals:\n",
    "        result.append(val_to_token_dict[val])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "religious-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(tokens, token_to_val_dict):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token_to_val_dict[token])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thousand-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"h3_tokens\"] = data[\"H3_POLYLINE\"].apply(lambda x: tokenize(x, h3_to_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "olive-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vocab = data[\"h3_tokens\"].explode().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chubby-terry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>H3_POLYLINE</th>\n",
       "      <th>h3_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1393410053620000386</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000386</td>\n",
       "      <td>1393410053</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.58564,41.148621],[-8.585712,41.148783],[-...</td>\n",
       "      <td>[897b63370bbffff, 897b6337087ffff, 897b633754b...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1388414676620000406</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20000406</td>\n",
       "      <td>1388414676</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.582238,41.180634],[-8.582229,41.180634],[...</td>\n",
       "      <td>[897b63376c7ffff, 897b63376cfffff, 897b6337657...</td>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1397662736620000081</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000081</td>\n",
       "      <td>1397662736</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.599689,41.153103],[-8.599698,41.153094],[...</td>\n",
       "      <td>[897b6337437ffff, 897b63375dbffff, 897b63375cb...</td>\n",
       "      <td>[30, 31, 32, 33, 34, 35, 3, 2, 36, 35, 33, 32,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1403885169620000669</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000669</td>\n",
       "      <td>1403885169</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610948,41.145723],[-8.610777,41.14593],[-...</td>\n",
       "      <td>[897b63adb67ffff, 897b63adb6fffff, 897b63adb67...</td>\n",
       "      <td>[46, 47, 46, 48, 49, 50, 51, 45, 52, 53, 54, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1382026245620000163</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000163</td>\n",
       "      <td>1382026245</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.632719,41.151582],[-8.632665,41.151672],[...</td>\n",
       "      <td>[897b63adb97ffff, 897b63ad82fffff, 897b63adb93...</td>\n",
       "      <td>[62, 63, 64, 63, 65, 66, 67, 68, 69, 70, 67, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "0  1393410053620000386         B          NaN          15.0  20000386   \n",
       "1  1388414676620000406         B          NaN           6.0  20000406   \n",
       "2  1397662736620000081         C          NaN           NaN  20000081   \n",
       "3  1403885169620000669         B          NaN          57.0  20000669   \n",
       "4  1382026245620000163         C          NaN           NaN  20000163   \n",
       "\n",
       "    TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "0  1393410053        A         False   \n",
       "1  1388414676        A         False   \n",
       "2  1397662736        A         False   \n",
       "3  1403885169        A         False   \n",
       "4  1382026245        A         False   \n",
       "\n",
       "                                            POLYLINE  \\\n",
       "0  [[-8.58564,41.148621],[-8.585712,41.148783],[-...   \n",
       "1  [[-8.582238,41.180634],[-8.582229,41.180634],[...   \n",
       "2  [[-8.599689,41.153103],[-8.599698,41.153094],[...   \n",
       "3  [[-8.610948,41.145723],[-8.610777,41.14593],[-...   \n",
       "4  [[-8.632719,41.151582],[-8.632665,41.151672],[...   \n",
       "\n",
       "                                         H3_POLYLINE  \\\n",
       "0  [897b63370bbffff, 897b6337087ffff, 897b633754b...   \n",
       "1  [897b63376c7ffff, 897b63376cfffff, 897b6337657...   \n",
       "2  [897b6337437ffff, 897b63375dbffff, 897b63375cb...   \n",
       "3  [897b63adb67ffff, 897b63adb6fffff, 897b63adb67...   \n",
       "4  [897b63adb97ffff, 897b63ad82fffff, 897b63adb93...   \n",
       "\n",
       "                                           h3_tokens  \n",
       "0                     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
       "1  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2...  \n",
       "2  [30, 31, 32, 33, 34, 35, 3, 2, 36, 35, 33, 32,...  \n",
       "3  [46, 47, 46, 48, 49, 50, 51, 45, 52, 53, 54, 5...  \n",
       "4  [62, 63, 64, 63, 65, 66, 67, 68, 69, 70, 67, 7...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-smooth",
   "metadata": {},
   "source": [
    "### Skipgram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "according-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ids = data.loc[88, \"H3_POLYLINE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "boolean-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inp = list(range(1, 6))\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-management",
   "metadata": {},
   "source": [
    "#### Positive pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "reasonable-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_pairs(seq, window_size=3):\n",
    "    pairs = []\n",
    "    for i in range(len(seq)):\n",
    "        for j in reversed(range(1, window_size+1)):\n",
    "            new_idx = i - j\n",
    "            if new_idx >= 0:\n",
    "                pairs.append([seq[i], seq[new_idx], 1])\n",
    "        for k in range(1, window_size+1):\n",
    "            new_idx = i + k\n",
    "            if new_idx < len(seq):\n",
    "                pairs.append([seq[i], seq[new_idx], 1])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "broad-uganda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.555152893066406e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "temp_pos_pairs = get_positive_pairs(test_inp)\n",
    "print(time.time() - start_time)\n",
    "temp_pos_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "serial-southwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.657780408859253\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data[\"h3_tokens\"] = data[\"h3_tokens\"].apply(lambda x: get_positive_pairs(x, 2))\n",
    "data = data.explode(\"h3_tokens\")\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-penny",
   "metadata": {},
   "source": [
    "#### Get negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "maritime-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_sample(positive_pair, vocab, num_pairs=2):\n",
    "    try:\n",
    "        target = positive_pair[0]\n",
    "    except:\n",
    "        print(positive_pair)\n",
    "    contexts = [positive_pair[1]]\n",
    "    labels = [1]\n",
    "    while True:\n",
    "        neg_context = np.random.choice(vocab, size=1)[0]\n",
    "        if neg_context not in positive_pair:\n",
    "            contexts.append(neg_context)\n",
    "            labels.append(0)\n",
    "        if len(contexts) == num_pairs + 1:\n",
    "            break\n",
    "            \n",
    "    c_l = list(zip(contexts, labels))\n",
    "    random.shuffle(c_l)\n",
    "    contexts, labels = zip(*c_l)\n",
    "\n",
    "    return target, *contexts, *labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cloudy-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pos = temp_pos_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "latin-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0037622451782226562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 756, 53, 2, 0, 0, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "temp_neg_pairs = get_training_sample(temp_pos, token_vocab, 2)\n",
    "print(time.time() - start_time)\n",
    "temp_neg_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-productivity",
   "metadata": {},
   "source": [
    "### Creating training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "macro-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_skipgram_data_mp(token_pairs, token_vocab, num_neg_sample):\n",
    "    pool = mp.Pool(processes=8)\n",
    "    result = pool.starmap_async(get_training_sample, zip(token_pairs, itertools.repeat(token_vocab), itertools.repeat(num_neg_sample)))\n",
    "    result = np.array(result.get())\n",
    "    targets = np.expand_dims(result[:, 0], 1)\n",
    "    contexts = result[:, 1:num_neg_sample+2]\n",
    "    labels = result[:, num_neg_sample+2:]\n",
    "    return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_indices(data_len, batch_sz):\n",
    "    batches = []\n",
    "    num_batches = math.ceil(data_len / batch_sz)\n",
    "    for i in range(num_batches):\n",
    "        batches.append((i*batch_sz, (i+1)*batch_sz))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "scientific-amplifier",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995.5299608707428\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_targets, train_contexts, train_labels = tokens_to_skipgram_data_mp(data.h3_tokens, token_vocab, 2)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-given",
   "metadata": {},
   "source": [
    "## Making Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-windows",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_targets_tensor = torch.tensor(train_targets)\n",
    "train_contexts_tensor = torch.tensor(train_contexts)\n",
    "train_labels_tensor = torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_targets_tensor.shape)\n",
    "print(train_contexts_tensor.shape)\n",
    "print(train_labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_targets_tensor, \"../data/subset_train_targets.pt\")\n",
    "torch.save(train_contexts_tensor, \"../data/subset_train_contexts.pt\")\n",
    "torch.save(train_labels_tensor, \"../data/subset_train_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-operations",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
