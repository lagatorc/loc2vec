{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "electric-edmonton",
   "metadata": {},
   "source": [
    "- Batch the dataframe by a few thousand and write tensors to a directory\n",
    "- Use that directory to train the model, Pytorch dataset can data file names as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "delayed-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import h3\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virtual-multiple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1381408427620000361</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000361</td>\n",
       "      <td>1381408427</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.626437,41.152185],[-8.625753,41.152428],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1402587497620000166</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000166</td>\n",
       "      <td>1402587497</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.617113,41.143815],[-8.615349,41.147172],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1399759179620000664</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000664</td>\n",
       "      <td>1399759179</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.616276,41.147082],[-8.61741,41.147217],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1383443307620000305</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000305</td>\n",
       "      <td>1383443307</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.611002,41.146056],[-8.610831,41.145993],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1402355881620000288</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>20000288</td>\n",
       "      <td>1402355881</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.630253,41.157342],[-8.629686,41.157036],[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "0  1381408427620000361         C          NaN           NaN  20000361   \n",
       "1  1402587497620000166         C          NaN           NaN  20000166   \n",
       "2  1399759179620000664         C          NaN           NaN  20000664   \n",
       "3  1383443307620000305         B          NaN          57.0  20000305   \n",
       "4  1402355881620000288         B          NaN          54.0  20000288   \n",
       "\n",
       "    TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "0  1381408427        A         False   \n",
       "1  1402587497        A         False   \n",
       "2  1399759179        A         False   \n",
       "3  1383443307        A         False   \n",
       "4  1402355881        A         False   \n",
       "\n",
       "                                            POLYLINE  \n",
       "0  [[-8.626437,41.152185],[-8.625753,41.152428],[...  \n",
       "1  [[-8.617113,41.143815],[-8.615349,41.147172],[...  \n",
       "2  [[-8.616276,41.147082],[-8.61741,41.147217],[-...  \n",
       "3  [[-8.611002,41.146056],[-8.610831,41.145993],[...  \n",
       "4  [[-8.630253,41.157342],[-8.629686,41.157036],[...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/original_data.csv\")\n",
    "data = data.sample(35000)\n",
    "data = data.reset_index(drop=True)\n",
    "#data = pd.read_csv(\"../data/subset_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accredited-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(data)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recognized-rouge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples / 25000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-speaking",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/crailtap/taxi-trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-acting",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latest-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeats(vals):\n",
    "    if len(vals) == 0:\n",
    "        return None\n",
    "    result = []\n",
    "    curr = vals[0]\n",
    "    for val in vals[1:]:\n",
    "        if val != curr:\n",
    "            result.append(curr)\n",
    "        curr = val\n",
    "    result.append(curr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "frank-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlon_to_h3(latlons, res=9):\n",
    "    latlons = ast.literal_eval(latlons)\n",
    "    result = []\n",
    "    for latlon in latlons:\n",
    "        h3_id = h3.geo_to_h3(latlon[0], latlon[1], res)\n",
    "        result.append(h3_id)\n",
    "    result = remove_repeats(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-truck",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-leisure",
   "metadata": {},
   "source": [
    "### Convert to H3 Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complimentary-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"H3_POLYLINE\"] = data[\"POLYLINE\"].apply(latlon_to_h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "continued-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0, subset=[\"H3_POLYLINE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attempted-convertible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677354\n"
     ]
    }
   ],
   "source": [
    "data[\"len_h3\"] = data[\"H3_POLYLINE\"].apply(len)\n",
    "data = data[data[\"len_h3\"] > 1]\n",
    "print(data[\"len_h3\"].sum())\n",
    "data = data.drop(columns=[\"len_h3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-booth",
   "metadata": {},
   "source": [
    "### Tokenizing H3 IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latest-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_h3_ids = data.explode(\"H3_POLYLINE\").H3_POLYLINE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "juvenile-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_to_token = {}\n",
    "token_to_h3 = {}\n",
    "for i in range(len(unq_h3_ids)):\n",
    "    h3_to_token[unq_h3_ids[i]] = i\n",
    "    token_to_h3[i] = unq_h3_ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "impressive-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/tokenizers/encode_h3_to_token.pickle\", \"wb\") as f:\n",
    "    pickle.dump(h3_to_token, f)\n",
    "with open(\"../models/tokenizers/decode_token_to_h3.pickle\", \"wb\") as f:\n",
    "    pickle.dump(token_to_h3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "experimental-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(vals, val_to_token_dict):\n",
    "    result = []\n",
    "    for val in vals:\n",
    "        result.append(val_to_token_dict[val])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "crucial-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(tokens, token_to_val_dict):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token_to_val_dict[token])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "governing-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"h3_tokens\"] = data[\"H3_POLYLINE\"].apply(lambda x: tokenize(x, h3_to_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "monetary-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vocab = data[\"h3_tokens\"].explode().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "automotive-height",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>H3_POLYLINE</th>\n",
       "      <th>h3_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1381408427620000361</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000361</td>\n",
       "      <td>1381408427</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.626437,41.152185],[-8.625753,41.152428],[...</td>\n",
       "      <td>[897b63adb8fffff, 897b63adb8bffff, 897b63adb9b...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 2, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1402587497620000166</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000166</td>\n",
       "      <td>1402587497</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.617113,41.143815],[-8.615349,41.147172],[...</td>\n",
       "      <td>[897b63adb23ffff, 897b63adb3bffff]</td>\n",
       "      <td>[6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1399759179620000664</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000664</td>\n",
       "      <td>1399759179</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.616276,41.147082],[-8.61741,41.147217],[-...</td>\n",
       "      <td>[897b63adb3bffff, 897b63adb07ffff, 897b63adbab...</td>\n",
       "      <td>[7, 8, 9, 10, 0, 11, 12, 13, 14, 15, 16, 17, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1383443307620000305</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000305</td>\n",
       "      <td>1383443307</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.611002,41.146056],[-8.610831,41.145993],[...</td>\n",
       "      <td>[897b63adb67ffff, 897b63adb6fffff, 897b63adb67...</td>\n",
       "      <td>[19, 20, 19, 21, 22, 23, 6, 23, 24, 23, 25, 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1402355881620000288</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>20000288</td>\n",
       "      <td>1402355881</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.630253,41.157342],[-8.629686,41.157036],[...</td>\n",
       "      <td>[897b63ad867ffff, 897b63adb9bffff, 897b63adb83...</td>\n",
       "      <td>[4, 2, 11, 0, 10, 9, 8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "0  1381408427620000361         C          NaN           NaN  20000361   \n",
       "1  1402587497620000166         C          NaN           NaN  20000166   \n",
       "2  1399759179620000664         C          NaN           NaN  20000664   \n",
       "3  1383443307620000305         B          NaN          57.0  20000305   \n",
       "4  1402355881620000288         B          NaN          54.0  20000288   \n",
       "\n",
       "    TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "0  1381408427        A         False   \n",
       "1  1402587497        A         False   \n",
       "2  1399759179        A         False   \n",
       "3  1383443307        A         False   \n",
       "4  1402355881        A         False   \n",
       "\n",
       "                                            POLYLINE  \\\n",
       "0  [[-8.626437,41.152185],[-8.625753,41.152428],[...   \n",
       "1  [[-8.617113,41.143815],[-8.615349,41.147172],[...   \n",
       "2  [[-8.616276,41.147082],[-8.61741,41.147217],[-...   \n",
       "3  [[-8.611002,41.146056],[-8.610831,41.145993],[...   \n",
       "4  [[-8.630253,41.157342],[-8.629686,41.157036],[...   \n",
       "\n",
       "                                         H3_POLYLINE  \\\n",
       "0  [897b63adb8fffff, 897b63adb8bffff, 897b63adb9b...   \n",
       "1                 [897b63adb23ffff, 897b63adb3bffff]   \n",
       "2  [897b63adb3bffff, 897b63adb07ffff, 897b63adbab...   \n",
       "3  [897b63adb67ffff, 897b63adb6fffff, 897b63adb67...   \n",
       "4  [897b63ad867ffff, 897b63adb9bffff, 897b63adb83...   \n",
       "\n",
       "                                           h3_tokens  \n",
       "0                              [0, 1, 2, 3, 4, 2, 5]  \n",
       "1                                             [6, 7]  \n",
       "2   [7, 8, 9, 10, 0, 11, 12, 13, 14, 15, 16, 17, 18]  \n",
       "3  [19, 20, 19, 21, 22, 23, 6, 23, 24, 23, 25, 26...  \n",
       "4                            [4, 2, 11, 0, 10, 9, 8]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-guard",
   "metadata": {},
   "source": [
    "### Skipgram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "approved-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ids = data.loc[88, \"H3_POLYLINE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "saving-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inp = list(range(1, 6))\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-belarus",
   "metadata": {},
   "source": [
    "#### Positive pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "small-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_pairs(seq, window_size=3):\n",
    "    pairs = []\n",
    "    for i in range(len(seq)):\n",
    "        for j in reversed(range(1, window_size+1)):\n",
    "            new_idx = i - j\n",
    "            if new_idx >= 0:\n",
    "                pairs.append([seq[i], seq[new_idx], 1])\n",
    "        for k in range(1, window_size+1):\n",
    "            new_idx = i + k\n",
    "            if new_idx < len(seq):\n",
    "                pairs.append([seq[i], seq[new_idx], 1])\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "legitimate-austin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.745887756347656e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "temp_pos_pairs = get_positive_pairs(test_inp)\n",
    "print(time.time() - start_time)\n",
    "temp_pos_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "monthly-coupon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.369764804840088\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data[\"h3_tokens\"] = data[\"h3_tokens\"].apply(lambda x: get_positive_pairs(x, 2))\n",
    "data = data.explode(\"h3_tokens\")\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-fashion",
   "metadata": {},
   "source": [
    "#### Get negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "registered-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_sample(positive_pair, vocab, num_pairs=2):\n",
    "    try:\n",
    "        target = positive_pair[0]\n",
    "    except:\n",
    "        print(positive_pair)\n",
    "    contexts = [positive_pair[1]]\n",
    "    labels = [1]\n",
    "    while True:\n",
    "        neg_context = np.random.choice(vocab, size=1)[0]\n",
    "        if neg_context not in positive_pair:\n",
    "            contexts.append(neg_context)\n",
    "            labels.append(0)\n",
    "        if len(contexts) == num_pairs + 1:\n",
    "            break\n",
    "            \n",
    "    c_l = list(zip(contexts, labels))\n",
    "    random.shuffle(c_l)\n",
    "    contexts, labels = zip(*c_l)\n",
    "\n",
    "    return target, *contexts, *labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "angry-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pos = temp_pos_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "musical-assumption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020775794982910156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 4272, 2110, 2, 0, 0, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "temp_neg_pairs = get_training_sample(temp_pos, token_vocab, 2)\n",
    "print(time.time() - start_time)\n",
    "temp_neg_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-advice",
   "metadata": {},
   "source": [
    "### Creating training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "assigned-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_skipgram_data_mp(token_pairs, token_vocab, num_neg_sample):\n",
    "    pool = mp.Pool(processes=8)\n",
    "    result = pool.starmap_async(get_training_sample, zip(token_pairs, itertools.repeat(token_vocab), itertools.repeat(num_neg_sample)))\n",
    "    result = np.array(result.get())\n",
    "    targets = np.expand_dims(result[:, 0], 1)\n",
    "    contexts = result[:, 1:num_neg_sample+2]\n",
    "    labels = result[:, num_neg_sample+2:]\n",
    "    return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "final-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_indices(data_len, batch_sz):\n",
    "    batches = []\n",
    "    num_batches = math.ceil(data_len / batch_sz)\n",
    "    for i in range(num_batches):\n",
    "        batches.append((i*batch_sz, (i+1)*batch_sz))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "boolean-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = get_batch_indices(len(data), 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "suspected-miniature",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220.2296116352081\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_targets, train_contexts, train_labels = tokens_to_skipgram_data_mp(data.h3_tokens, token_vocab, 2)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-paris",
   "metadata": {},
   "source": [
    "## Making Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-heating",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_targets_tensor = torch.tensor(train_targets)\n",
    "train_contexts_tensor = torch.tensor(train_contexts)\n",
    "train_labels_tensor = torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_targets_tensor.shape)\n",
    "print(train_contexts_tensor.shape)\n",
    "print(train_labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_targets_tensor, \"../data/subset_train_targets.pt\")\n",
    "torch.save(train_contexts_tensor, \"../data/subset_train_contexts.pt\")\n",
    "torch.save(train_labels_tensor, \"../data/subset_train_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
